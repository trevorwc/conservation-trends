{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_E6KFTwGFIOZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"GPU is available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anR06KQ-VEZ3"
      },
      "source": [
        "Embeddings for policy articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoXLdFFNS--N"
      },
      "outputs": [],
      "source": [
        "pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsfRCLIsTjUa"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Set up stop words\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "# Configure vectorizer and load data\n",
        "vectorizer_model = CountVectorizer(stop_words=stop_words, ngram_range=(1, 2))\n",
        "data = pd.read_json('/content/ecolex_filtered_articles_with_dates.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHP3JcDFT2iW"
      },
      "outputs": [],
      "source": [
        "# Flatten the 'articles' column to extract nested fields\n",
        "articles_flattened = pd.json_normalize(data[\"articles\"])\n",
        "\n",
        "# Verify columns in the flattened data\n",
        "print(articles_flattened.columns)\n",
        "\n",
        "# Ensure the 'abstract' field exists\n",
        "if 'abstract' in articles_flattened.columns:\n",
        "    # Filter rows with non-null abstracts\n",
        "    articles_with_abstracts = articles_flattened[articles_flattened[\"abstract\"].notna()]\n",
        "else:\n",
        "    raise KeyError(\"The 'abstract' column is missing in the articles data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0FPPf9xT5q7"
      },
      "outputs": [],
      "source": [
        "# Initialize embedding model and BERTopic\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "topic_model = BERTopic(embedding_model=embedding_model, vectorizer_model=vectorizer_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPVf_AeGT92A"
      },
      "outputs": [],
      "source": [
        "# Fit-transform and extract topics and probabilities\n",
        "topics, probabilities = topic_model.fit_transform(articles_with_abstracts['abstract'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2DOgOmbUEk9"
      },
      "outputs": [],
      "source": [
        "# Add topics and probabilities to the DataFrame\n",
        "articles_with_abstracts['topic'] = topics\n",
        "articles_with_abstracts['probability'] = probabilities\n",
        "\n",
        "# Get topic information and merge with the DataFrame\n",
        "topic_info = topic_model.get_topic_info()\n",
        "topic_info.rename(columns={'Topic': 'topic'}, inplace=True)\n",
        "articles_with_abstracts = articles_with_abstracts.merge(topic_info[['topic', 'Name']], on='topic', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1L9JowHSQw2"
      },
      "outputs": [],
      "source": [
        "# Generate embeddings for the abstracts and add them to the DataFrame\n",
        "embeddings = embedding_model.encode(articles_with_abstracts['abstract'].tolist(), show_progress_bar=True)\n",
        "articles_with_abstracts['embedding'] = embeddings.tolist()\n",
        "\n",
        "# Save the DataFrame to a JSON file\n",
        "articles_with_abstracts.to_json('ecolex_filtered_bertopic_with_embeddings.json',\n",
        "                                orient='records',\n",
        "                                indent=4)\n",
        "# Download the file\n",
        "from google.colab import files\n",
        "files.download('ecolex_filtered_bertopic_with_embeddings.json')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87WM-5bJVBU9"
      },
      "source": [
        "Embeddings for scientific articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uprJmDjyvGq2"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6zIJya8Uv2s"
      },
      "outputs": [],
      "source": [
        "# Set up stop words\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "# Configure vectorizer and load data\n",
        "vectorizer_model = CountVectorizer(stop_words=stop_words, ngram_range=(1, 2))\n",
        "cdf_subs = pd.read_json('/content/conservation_filtered.json')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSRtHBbzU02P"
      },
      "outputs": [],
      "source": [
        "# Initialize embedding model and BERTopic\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "topic_model = BERTopic(embedding_model=embedding_model, vectorizer_model=vectorizer_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iFHT3UfU1wZ"
      },
      "outputs": [],
      "source": [
        "# Fit-transform and extract topics and probabilities\n",
        "topics, probabilities = topic_model.fit_transform(cdf_subs['abstract'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhfelxfJU4yl"
      },
      "outputs": [],
      "source": [
        "# Add topics and probabilities to the DataFrame\n",
        "cdf_subs['topic'] = topics\n",
        "cdf_subs['probability'] = probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUQSDmSzU6gv"
      },
      "outputs": [],
      "source": [
        "# Get topic information and merge with the DataFrame\n",
        "topic_info = topic_model.get_topic_info()\n",
        "topic_info.rename(columns={'Topic': 'topic'}, inplace=True)\n",
        "cdf_subs = cdf_subs.merge(topic_info[['topic', 'Name']], on='topic', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_CSLU-BU8Lj"
      },
      "outputs": [],
      "source": [
        "# Generate embeddings for the abstracts and add them to the DataFrame\n",
        "embeddings = embedding_model.encode(cdf_subs['abstract'].tolist(), show_progress_bar=True)\n",
        "cdf_subs['embedding'] = embeddings.tolist()\n",
        "\n",
        "cdf_subs.to_json('conservation_filtered_bertopic_with_embeddings.json',\n",
        "                 orient='records',\n",
        "                 indent=4)\n",
        "\n",
        "# Download the file\n",
        "from google.colab import files\n",
        "files.download('conservation_filtered_bertopic_with_embeddings.json')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "cd3544ba632fead972994b92dd2aabdc5f410d0534469344678817c83fab6a76"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
